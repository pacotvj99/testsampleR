<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Vignette of testsampleR package</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Vignette of testsampleR package</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(testsampleR)</span></code></pre></div>
<p>This vignette illustrates how to use the <code>testsampleR</code>
package, with a start-to-finish illustration of its core
functionalities. This package is designed to help users evaluate their
machine learning classifiers on a test set. Specifically, the package
allows users to rigorously determine the appropriate size of a test set,
draw test sets with a stratified approach that yields more precise
performance estimates, and quantify uncertainty around estimates with
appropriate standard errors or confidence intervals. Together, these
tools help researchers make more informative and rigorous claims about
how well a classifier performed in a specific application.</p>
<p>In this example application, we have a population of online comments
that we have put through a hate speech detection classifier: the numbers
in <code>score</code> denote the probability that a comment contains
hate speech, as predicted by a classifier. We will load and use this
data for illustration.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">data</span>(pop_df)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">head</span>(pop_df)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co">#&gt;   id      score</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co">#&gt; 1  1 0.43900311</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">#&gt; 2  2 0.32769549</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co">#&gt; 3  3 0.12400556</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt; 4  4 0.05128729</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">#&gt; 5  5 0.82628548</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt; 6  6 0.09824443</span></span></code></pre></div>
<p>We want to use a test set to learn how well our hate speech
classifier performed in this context. Importantly, none of the
observations in the data have been used to train the hate speech
classifier: this means that the data we are inspecting has not been seen
by the model. This can happen either because we are using some
off-the-shelf classifier (e.g. Google’s Perspective), or because we
trained on some other data (e.g. sampled the training set and test set
separately). How big a test set should we draw? That depends on three
things: (i) what metrics we care about, (ii) how imbalanced the data is,
(iii) what performance we expect.</p>
<p>Regarding point (i), let’s say that we care about the F1 score. Test
sets are costly to annotate (in terms of time or money), so we want to
sample the smallest test set possible, given how much variance we are
willing to accept around the F1. Let’s say we are willing to accept a
2pp standard error for the F1 score. Regarding point (ii), the imbalance
can be observed directly from the data: we can check what proportion of
observations are positive. Assuming that we dichotomize classifications
at the 0.5 threshold, the proportion of positives is:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>positive_share <span class="ot">&lt;-</span> <span class="fu">mean</span>(pop_df<span class="sc">$</span>score<span class="sc">&gt;</span><span class="fl">0.5</span>)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>positive_share</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co">#&gt; [1] 0.18395</span></span></code></pre></div>
<p>Lastly, regarding point (iii), we need to make some guesses about
what performance we expect the classifier to have. We can base these on
previous experience with similar tasks, or on the excluded folds in the
training’s cross-validation, or on previous performance of the
classifier as established by other people’s validations. Let’s say that
we expect precision of 0.6 and recall of 0.5. This means that we expect
the classifier to catch 60% of the actually hateful comments, and that
50% of comments flagged as hateful by the classifier will truly be so.
Given all this information, we can use function
<code>test_samplesize</code> to determine how large a test set we need
to draw:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">test_samplesize</span>(<span class="at">se_f1 =</span> <span class="fl">0.02</span>, <span class="at">pi1 =</span> <span class="fl">0.6</span>, <span class="at">recall =</span> <span class="fl">0.5</span>, <span class="at">positive_share =</span> positive_share)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">#&gt; In-sample imbalance assumed to estimate pi0</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co">#&gt; $srs</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">#&gt;   precision_se_srs recall_se_srs  f1_se_srs sample_size_srs</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#&gt; 1       0.02419904    0.02254612 0.01999921            2228</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co">#&gt; $stratified</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">#&gt;   precision_se_strat recall_se_strat f1_se_strat n_positives sample_size_strat</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co">#&gt; 1         0.02057378      0.02607442  0.01999337         567              1226</span></span></code></pre></div>
<p>The results show that if we drew the test set as a simple random
sample, we would need 2228 observations to achieve the desired SE. If we
use efficient stratification instead, we only need 1226 observations! To
achieve this efficiency gains, we are advised to sample 567 positives
and 659 negatives.</p>
<p>If we decide to use efficient stratification, we can then use the
<code>testsampler</code> function to actually draw the test set. To reap
some additional reductions in variance, we will use a finer strata: we
will subdivide the positive and negative subsamples in 5 bins each,
resulting in 10 bins in total. Given that we want to use efficient
stratification, we need to set <code>allocation</code> to ‘optimal’, and
specify what the stratifying variable is (<code>score</code>), as well
as our desired sample size, which we calculated earlier. The output will
be a dataframe containing our test-set observations.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># we can specify the number of positives to be sampled: the 567 derived above</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>testset <span class="ot">&lt;-</span> <span class="fu">testsampler</span>(<span class="at">data =</span> pop_df, <span class="at">stratifying =</span> <span class="st">&quot;score&quot;</span>, <span class="at">N_sample =</span> <span class="dv">1226</span>, </span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>                       <span class="at">allocation =</span> <span class="st">&quot;optimal&quot;</span>, <span class="at">n_positive =</span> <span class="dv">567</span>, <span class="at">seed =</span> <span class="dv">1234</span>)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">#&gt; Optimal allocation with pre-specified number of positives</span></span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co"># alternatively, we can enter the parameters we entered earlier. the result is the same</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>testset <span class="ot">&lt;-</span> <span class="fu">testsampler</span>(<span class="at">data =</span> pop_df, <span class="at">stratifying =</span> <span class="st">&quot;score&quot;</span>, <span class="at">N_sample =</span> <span class="dv">1226</span>, </span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>                       <span class="at">allocation =</span> <span class="st">&quot;optimal&quot;</span>, <span class="at">pi1 =</span> <span class="fl">0.6</span>, <span class="at">recall =</span> <span class="fl">0.5</span>, <span class="at">seed =</span> <span class="dv">1234</span>)</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt; In-sample imbalance assumed to estimate pi0</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">head</span>(testset)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co">#&gt;          id     score stratifying id_sampling    strata       Prob</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co">#&gt; 9924   9924 0.7008861   0.7008861        9924 (0.7,0.8) 0.15432873</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co">#&gt; 9204   9204 0.8140863   0.8140863        9204 (0.8,0.9) 0.15490534</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co">#&gt; 7719   7719 0.7565815   0.7565815        7719 (0.7,0.8) 0.15432873</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co">#&gt; 5185   5185 0.4639310   0.4639310        5185 (0.4,0.5) 0.04013378</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="co">#&gt; 12373 12373 0.6112838   0.6112838       12373 (0.6,0.7) 0.15410574</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co">#&gt; 15100 15100 0.4885200   0.4885200       15100 (0.4,0.5) 0.04013378</span></span></code></pre></div>
<p>Now we have drawn a stratified test set, using efficient
stratification. We could have drawn the test set using other
stratification approaches. For instance, we could have used constant
stratification, which samples the same number of observations in each
stratum. Or proportional stratification, which samples from each stratum
in proportion to their size in the population. Or we could have used
simple random sampling. You can see below how to implement these
approaches, and a comparison of how the distribution of sampled
observations differs across test sets: this shows that efficient
allocation allows us to sample more positives than SRS.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># proportional stratification</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>prop_testset <span class="ot">&lt;-</span> <span class="fu">testsampler</span>(<span class="at">data =</span> pop_df, <span class="at">stratifying =</span> <span class="st">&quot;score&quot;</span>, <span class="at">N_sample =</span> <span class="dv">1226</span>,</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>                            <span class="at">allocation =</span> <span class="st">&quot;proportional&quot;</span>, <span class="at">seed =</span> <span class="dv">1234</span>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co"># constant stratification</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>const_testset <span class="ot">&lt;-</span> <span class="fu">testsampler</span>(<span class="at">data =</span> pop_df, <span class="at">stratifying =</span> <span class="st">&quot;score&quot;</span>, <span class="at">N_sample =</span> <span class="dv">1226</span>, </span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>                             <span class="at">allocation =</span> <span class="st">&quot;constant&quot;</span>, <span class="at">seed =</span> <span class="dv">1234</span>)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co"># no stratification: simple random sample</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>srs_testset <span class="ot">&lt;-</span> pop_df[<span class="fu">sample</span>(<span class="fu">nrow</span>(pop_df), <span class="dv">1226</span>),]</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co"># comparison of the different distribution of observations for different sampling</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="fu">table</span>(testset<span class="sc">$</span>strata)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co">#&gt;   (0,0.1) (0.1,0.2) (0.2,0.3) (0.3,0.4) (0.4,0.5) (0.5,0.6) (0.6,0.7) (0.7,0.8) (0.8,0.9)   (0.9,1) </span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="co">#&gt;       313       149        88        61        48       166       137       123        90        51</span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">table</span>(prop_testset<span class="sc">$</span>strata)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co">#&gt;   (0,0.1) (0.1,0.2) (0.2,0.3) (0.3,0.4) (0.4,0.5) (0.5,0.6) (0.6,0.7) (0.7,0.8) (0.8,0.9)   (0.9,1) </span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co">#&gt;       474       227       134        93        73        66        54        49        36        20</span></span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">table</span>(const_testset<span class="sc">$</span>strata)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">#&gt;   (0,0.1) (0.1,0.2) (0.2,0.3) (0.3,0.4) (0.4,0.5) (0.5,0.6) (0.6,0.7) (0.7,0.8) (0.8,0.9)   (0.9,1) </span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co">#&gt;       122       122       122       122       123       123       123       123       123       123</span></span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>srs_testset<span class="sc">$</span>strata <span class="ot">&lt;-</span> <span class="fu">cut</span>(srs_testset<span class="sc">$</span>score, <span class="at">breaks=</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>))</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="fu">table</span>(srs_testset<span class="sc">$</span>strata)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co">#&gt;   (0,0.1] (0.1,0.2] (0.2,0.3] (0.3,0.4] (0.4,0.5] (0.5,0.6] (0.6,0.7] (0.7,0.8] (0.8,0.9]   (0.9,1] </span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co">#&gt;       467       245       124        90        74        65        70        42        36        13</span></span></code></pre></div>
<p>Now we have drawn our test set. Let’s say we annotate it: if these
are online comments, we would identify whether the outcome of interest
is present or not. I’ll generate random annotations just for
illustration, but in any actual application, the annotations will of
course not be randomly generated.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>testset<span class="sc">$</span>truth <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">nrow</span>(testset), <span class="dv">1</span>, testset<span class="sc">$</span>score)</span></code></pre></div>
<p>We now want to create metrics that show how well or badly our
classifier performs, as compared to our gold-standard annotations. We
can implement this using the <code>stratified_metrics</code> function.
We just need to enter our test set, and clarify which columns contain
the gold-standard annotations, the classifier annotations (continuous
probability or binary), and the sampling probabilities. The latter are
used to reweigh the annotations so that the test set remains
representative of the original population. The function would work with
any stratified test set: I illustrate this with the test set drawn with
efficient stratification.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># we can enter the continuous scores, along with a threshold for dichotomizing them</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="fu">stratified_metrics</span>(testset, <span class="st">&#39;truth&#39;</span>, <span class="st">&#39;score&#39;</span>, <span class="st">&#39;Prob&#39;</span>, <span class="at">threshold=</span><span class="fl">0.5</span>)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co">#&gt; Analytical SEs assume that stratification was done on the basis of positives vs negatives.</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co">#&gt; For other stratification regimes, use bootstrapping.</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">#&gt;          f1      f1_se precision precision_se    recall  recall_se negative_precision negative_recall</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co">#&gt; 1 0.5771318 0.01914705 0.6876017   0.01946396 0.4972446 0.02367257          0.8432864         0.92293</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co">#&gt;   negative_f1  accuracy       MCC     Kappa f1_unweighted f1_weighted        BM        TN        FN         FP</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">#&gt; 1   0.8813125 0.8146482 0.4722983 0.4623394     0.7292222   0.8039379 0.4201746 0.6881639 0.1278861 0.05746566</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">#&gt;          TP</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co">#&gt; 1 0.1264843</span></span></code></pre></div>
<p>The output contains metrics alongside their SEs. If we want
bootstrapped CIs, the function can also support these, but then we must
also enter the name of the variable containing the strata:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># we can enter the continuous scores, along with a threshold for dichotomizing them</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="fu">stratified_metrics</span>(<span class="at">data =</span> testset, <span class="at">truth =</span> <span class="st">&#39;truth&#39;</span>, <span class="at">pred =</span> <span class="st">&#39;score&#39;</span>, <span class="at">probs =</span> <span class="st">&#39;Prob&#39;</span>, </span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>                   <span class="at">threshold =</span> <span class="fl">0.5</span>, <span class="at">strata =</span> <span class="st">&#39;strata&#39;</span>, <span class="at">bs =</span> <span class="dv">300</span>)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co">#&gt; Analytical SEs assume that stratification was done on the basis of positives vs negatives.</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co">#&gt; For other stratification regimes, use bootstrapping.</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co">#&gt;          f1 f1_boot_se f1_boot_lwr f1_boot_upr      f1_se precision precision_boot_se precision_boot_lwr</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co">#&gt; 1 0.5771318 0.01785959   0.5469355   0.6162866 0.01914705 0.6876017        0.01712381          0.6558029</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co">#&gt;   precision_boot_upr precision_se    recall recall_boot_se recall_boot_lwr recall_boot_upr  recall_se</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a><span class="co">#&gt; 1           0.719349   0.01946396 0.4972446     0.02220928       0.4598981       0.5460948 0.02367257</span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a><span class="co">#&gt;   negative_precision negative_precision_boot_se negative_precision_boot_lwr negative_precision_boot_upr</span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="co">#&gt; 1          0.8432864                 0.01302841                     0.81821                   0.8691389</span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="co">#&gt;   negative_recall negative_recall_boot_se negative_recall_boot_lwr negative_recall_boot_upr negative_f1</span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a><span class="co">#&gt; 1         0.92293             0.004095268                 0.915509                0.9304186   0.8813125</span></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="co">#&gt;   negative_f1_boot_se negative_f1_boot_lwr negative_f1_boot_upr  accuracy accuracy_boot_se accuracy_boot_lwr</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a><span class="co">#&gt; 1         0.007913367            0.8667364            0.8973993 0.8146482       0.01125372          0.794446</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a><span class="co">#&gt;   accuracy_boot_upr       MCC MCC_boot_se MCC_boot_lwr MCC_boot_upr     Kappa Kappa_boot_se Kappa_boot_lwr</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a><span class="co">#&gt; 1         0.8375234 0.4722983   0.0231154    0.4329305    0.5228227 0.4623394    0.02439825      0.4199703</span></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a><span class="co">#&gt;   Kappa_boot_upr f1_unweighted f1_unweighted_boot_se f1_unweighted_boot_lwr f1_unweighted_boot_upr f1_weighted</span></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a><span class="co">#&gt; 1      0.5164275     0.7292222            0.01268056              0.7069108              0.7569754   0.8039379</span></span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a><span class="co">#&gt;   f1_weighted_boot_se f1_weighted_boot_lwr f1_weighted_boot_upr        BM BM_boot_se BM_boot_lwr BM_boot_upr</span></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a><span class="co">#&gt; 1          0.01297203            0.7803006             0.830609 0.4201746 0.02478366   0.3775558   0.4754519</span></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a><span class="co">#&gt;          TN TN_boot_se TN_boot_lwr TN_boot_upr        FN FN_boot_se FN_boot_lwr FN_boot_upr         FP</span></span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a><span class="co">#&gt; 1 0.6881639 0.01063183   0.6677002   0.7092608 0.1278861 0.01063183   0.1067892   0.1483498 0.05746566</span></span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a><span class="co">#&gt;    FP_boot_se FP_boot_lwr FP_boot_upr        TP  TP_boot_se TP_boot_lwr TP_boot_upr</span></span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a><span class="co">#&gt; 1 0.003149925  0.05162576  0.06331505 0.1264843 0.003149925   0.1206349   0.1323242</span></span></code></pre></div>
<p>If we sampled the test set using simple random sampling (SRS), we
could also use <code>stratified_metrics</code> to compute metrics and
their standard errors. This is the most commonly drawn test set: if you
drew your training and test set together as a SRS from the population,
and partitioned them later, then your test set is also a SRS itself. In
the SRS case, the function also allows showing Wilson CIs, which have
better small-sample properties (coverage, overshoot) than bootstrapped
CIs. As you can see, the SEs are larger than what they would be had we
used stratified sampling: stratified sampling allows us to get less
noisy estimates of performance.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># we can enter the continuous scores, along with a threshold for dichotomizing them</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>srs_testset<span class="sc">$</span>truth <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">nrow</span>(srs_testset), <span class="dv">1</span>, srs_testset<span class="sc">$</span>score)</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="fu">stratified_metrics</span>(<span class="at">data =</span> srs_testset, <span class="at">truth =</span> <span class="st">&#39;truth&#39;</span>, <span class="at">pred =</span> <span class="st">&#39;score&#39;</span>, <span class="at">threshold =</span> <span class="fl">0.5</span>)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a><span class="co">#&gt; Warning in stratified_metrics(data = srs_testset, truth = &quot;truth&quot;, pred = &quot;score&quot;, : No probabilities in data:</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="co">#&gt; constant sampling probability assumed. This is a problem if stratified sampling was used for drawing test set,</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="co">#&gt; but it is fine if the test set is a SRS</span></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="co">#&gt;          f1      f1_se f1_wilson_lwr f1_wilson_upr precision precision_se precision_wilson_lwr</span></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="co">#&gt; 1 0.5697897 0.02589088     0.5185782     0.6195501  0.659292   0.03152651            0.5952996</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="co">#&gt;   precision_wilson_upr    recall  recall_se recall_wilson_lwr recall_wilson_upr negative_precision</span></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a><span class="co">#&gt; 1            0.7179598 0.5016835 0.02901278         0.4451622         0.5581618              0.852</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="co">#&gt;   negative_recall negative_f1  accuracy       MCC     Kappa f1_unweighted f1_weighted        BM        TN</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="co">#&gt; 1       0.9171152   0.8833593 0.8164763 0.4627401 0.4558678     0.7265745   0.8073966 0.4187987 0.6949429</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a><span class="co">#&gt;          FN         FP        TP</span></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a><span class="co">#&gt; 1 0.1207178 0.06280587 0.1215334</span></span></code></pre></div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
